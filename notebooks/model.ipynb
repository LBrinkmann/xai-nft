{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c09d1f7",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "top_folder = \"../data/top_collections\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b63bc4b4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from xai.utils.data import make_dir\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ea9fb01f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuts = [f'2022-0{i}-01' for i in range(1,4)]\n",
    "validation_days = 30\n",
    "training_days = 30*6\n",
    "\n",
    "periods = [\n",
    "    {\n",
    "        'training': {\n",
    "            'start': datetime.datetime.fromisoformat(cut) - datetime.timedelta(days=training_days),\n",
    "            'end': datetime.datetime.fromisoformat(cut)\n",
    "        },\n",
    "        'validation': {\n",
    "            'start': datetime.datetime.fromisoformat(cut),\n",
    "            'end': datetime.datetime.fromisoformat(cut) + datetime.timedelta(days=validation_days)\n",
    "        },\n",
    "        'period': cut\n",
    "    }\n",
    "    for cut in cuts\n",
    "]\n",
    "\n",
    "def select(df, start, end):\n",
    "    w = (\n",
    "        (df['timestamp'] < end) &\n",
    "        (df['timestamp'] >= start)\n",
    "    )\n",
    "    return df[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bb5c4fa7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_t = pd.read_parquet(os.path.join(top_folder, 'asset_traits.parquet'), engine='pyarrow')\n",
    "df_a = pd.read_parquet(os.path.join(top_folder, 'assets.parquet'), engine='pyarrow')\n",
    "\n",
    "df_s = pd.read_parquet(os.path.join(top_folder, 'sales_with_trend.parquet'), engine='pyarrow')\n",
    "\n",
    "\n",
    "df_s['outlier'] = ((df_s['price_eth'] < 0.8 * df_s['price_eth_floor_500']) | \n",
    "(df_s['price_eth'] > 4 * df_s['price_eth_ceiling_500']))\n",
    "\n",
    "df_s = df_s[~df_s['outlier']]\n",
    "df_s = df_s.dropna(subset=[\"timestamp\", 'price_eth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t['frequency'] = df_t['trait_count'] / 10000\n",
    "ranks = df_t['trait_type'].unique()\n",
    "ranks = sorted(ranks)\n",
    "ranks = {\n",
    "    i: r for i,r in enumerate(ranks)\n",
    "}\n",
    "df_t['rank'] = df_t['trait_type'].map(ranks)\n",
    "columns = ['trait_type', 'trait_value', 'trait_count', 'rank', 'frequency']\n",
    "df_tg = df_t.groupby('asset_id')[columns].apply(lambda df: df.to_dict(orient='records'))\n",
    "df_tg.name = 'traits'\n",
    "\n",
    "df_as = df_a.set_index('asset_id')[['token_id', 'collection',\n",
    "       'image_url', 'image_preview_url', 'image_thumbnail_url']]\n",
    "\n",
    "df_aa = df_as.join(df_tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d3be1f7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_t_enc = df_t.pivot_table(\n",
    "    index='asset_id', columns='trait_id', values='trait_value', aggfunc='count') \\\n",
    "    .fillna(0).astype(int)\n",
    "feature_names = df_t_enc.columns.tolist()\n",
    "df_t_enc = df_t_enc.reset_index()\n",
    "df_p_enr = df_t_enc.merge(df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dbe9ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_enr['log_price_eth_scaled_50'] = np.log(df_p_enr['price_eth_scaled_50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "50dfca34",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starting with 2022-01-01\n",
      "In-Sample R2 0.7888990194451074\n",
      "Out-Sample R2 -683081574248268.9\n",
      "In-Sample exp var 0.7888999040302298\n",
      "Out-Sample exp var -682215818471132.2\n",
      "Validation starting with 2022-02-01\n",
      "In-Sample R2 0.7582558369593333\n",
      "Out-Sample R2 0.5683933383248235\n",
      "In-Sample exp var 0.7582564101258242\n",
      "Out-Sample exp var 0.6027452184438364\n",
      "Validation starting with 2022-03-01\n",
      "In-Sample R2 0.7476465213105351\n",
      "Out-Sample R2 0.38092143172722814\n",
      "In-Sample exp var 0.7476488313878689\n",
      "Out-Sample exp var 0.3828784975152839\n"
     ]
    }
   ],
   "source": [
    "target = 'price_eth_scaled_50'\n",
    "\n",
    "df = df_p_enr[feature_names + [target, 'asset_id', 'timestamp']]\n",
    "\n",
    "for p in periods:\n",
    "    df_training = select(df, **p['training']).groupby('asset_id').mean()\n",
    "    df_validation = select(df, **p['validation']).groupby('asset_id').mean()\n",
    "    model = LinearRegression()\n",
    "    model.fit(df_training[feature_names], df_training[target])\n",
    "\n",
    "    train_pred = model.predict(df_training[feature_names])\n",
    "    val_pred = model.predict(df_validation[feature_names])\n",
    "\n",
    "    r2_train = r2_score(df_training[target], train_pred)\n",
    "    r2_val = r2_score(df_validation[target], val_pred)\n",
    "    expvar_train = explained_variance_score(df_training[target], train_pred)\n",
    "    expvar_val = explained_variance_score(df_validation[target], val_pred)\n",
    "\n",
    "    print(f'Validation starting with {p[\"period\"]}')\n",
    "    print(f'In-Sample R2 {r2_train}')\n",
    "    print(f'Out-Sample R2 {r2_val}')\n",
    "    print(f'In-Sample exp var {expvar_train}')\n",
    "    print(f'Out-Sample exp var {expvar_val}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6358d2b37cadaf68da9f88457ea7b9933bd525c81ef3c979dca47c51e7682d4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "input_path": "notebooks/model.ipynb",
   "output_path": "notebooks/model.ipynb",
   "parameters": {
    "top_folder": "../data/top_collections"
   },
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
